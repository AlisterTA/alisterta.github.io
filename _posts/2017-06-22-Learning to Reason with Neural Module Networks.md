---
layout: post
title: Learning to Reason with Neural Module Networks
---
دیروز با شروع به کار [BAIR]( http://bair.berkeley.edu/) (وب لاگ آزمایشگاه تحقیقات هوش مصنوعی دانشگاه بروکلین ) این تصمیم رو گرفتم که یه وبلاگ ایجاد کنم.در اولین پست خودم تصمیم گرفتم که اولین پست BAIR رو در وب لاگم قرار بدم .

فرض کنید داریم یک رباط خانگی ایجاد میکنیم و قصد ما از ایجاد این رباط پاسخ به سوالات در باره محیط اطرافمان است . ممکنه سوالاتی مثل سوالات زیر بپرسیم :
![_config.yml]({{ site.baseurl }}/images/1/1.png)

چطور میتونیم مطمین شیم که رباط ما میتونه به درستی به این سوالات پاسخ بده ؟ رویکرد رایج در یادگیری عمیق جمع آوری یک دیتا بیس با حجم عظیم از سوالات ، عکس ها و پاسخ ها است و آموزش یک شبکه عصبی که سوالات و عکس ها رو به صورت مستقیم به جواب ها نگاشت میده. اگه سوالات ما شبیه سوالی که در سمت چپ تصویر است باشند این مسئله یک مسئله رایج تشخیص اشیاء است که متد های معمول بسیر موثر خواهند بود:
![_config.yml]({{ site.baseurl }}/images/1/2.png)

اما این رویکرد برای سئوال زیر به درستی عمل نخواهد کرد:

![_config.yml]({{ site.baseurl }}/images/1/3.png)

شبکه ای که ما قبلا آموزش داده ایم بعد از تسلیم شدن رنگی که از همه رایج تر هست را پیش بینی میکند. چه چیزی این سوال رو سخت تر میکنه ؟با وجود اینکه عکس ما واضح تر است اما سوال نیاز به تعداد زیادی گام استدلال دارد . در این عکس مدل به جای تشخیص شئی اصلی در عکس بایستی ابتدا استوانه آبی رنگ رو پیدا کنه ، محل سایر اشیایی که اندازه برابر رو با استوانه ما داره رو انتخاب کنه و سپس رنگ اون رو مشخص کنه.
این یه محاسباتی پیچیده است ، محاسباتی که به طور خاص مربوط به سوالی که پرسیده شده است. س.الات متفاوت نیاز به مراحل متفاوت از گام ها برای حل شدن دارند.
پارادایم رایج در یادگیری عمیق رویکرد one size fits all است : یرای هر مسئله ای که ما در تلاش برای حل آن هستیم ، ما یک معماری ثابت را ایجاد میکنیم با این امید که بتواند اررتباطات بین ورودی و خروجی را ظبط کند و پارامتر هایی را برای مدل ثابت از داده های آموزش یاد بگیرد.

 اما استدلال های دنیای واقعی به این صورت کار نمیکند : این استدلال های شامل انواع متفاوتی از توانایی ها ، که از ترکیب روش های جدیدی برای هر چالش که ما به آن برمیخوریم است. پیزی که ما احتیاج داریم یک مدل است که به صورت پویا تعیین میکند که چگونه در مورد مسئله پیش روی آن استدلال کند ، یک شبکه که میتواند ساختار خود را در حال اجرا انتخاب کند . در این پست ما در مورد یک مجموعه جدید از مدل ها به نام شبکه های ماژول عصبی (NMNs) صحبت خواهیم کرد ، که یک رویکرد انعطاف پذیر را برای حل مشکل در نظر میگیرد که یادیگیری عمیق را بسیار موثر تر میکند.

پیش از این ، مراحل مختلفی برای حل پاسخ دادن به سوال بالا وجود دارند : پیدا کردن یک استوانه آبی ، پیدا کردن شیی با اندازه مشابه و در نهایت مشخص کردن رنگ آن. این مراحل رو میشه به صورت زیر نشان داد :

![_config.yml]({{ site.baseurl }}/images/1/4.png)

یک سوال متفاوت ممکنه شامل مجموعه متفاوتی از گام ها باشد. اگر ما سوال کنیم " چند شیی هم اندازه توپ است ؟" ، ما فلوچارتی مانند شکل زیر ممکن است داشته باشیم:

![_config.yml]({{ site.baseurl }}/images/1/5.png)

 عملیات اصلی مثل "مقایسه اندازه" بین سوالات اشتراک گذاشته میشوند ، اما در مسیر های مختلفی استفاده میشوند. ایده اصلی NMNs  این است که این اشتراک را آشگکار سازیم . ما از دو شبکه متفاوت برای جواب دادن به دو سوال بالا استفاده میکنیم  اما وزن ها را بین بین بخش های شبکه ها که عملیات مشابهی را انجام میدهند به اشتراک میگذاریم:
 
 ![_config.yml]({{ site.baseurl }}/images/1/6.png)
 
 چگونه میتوان مدلی  مانند این را یاد گرفت؟ به جای آموزش یک شبکه بزرگ بر روی تعداد زیادی از ورودی و خروجی ها ، ما در واقع تعداد زیادی از شبکه های متفاوتی را در یک زمان آموزش میدهیم در حالیکه پارامتر های آنها در جاهایی که مناسب است به یک دیگر گره خورده اند:

![_config.yml]({{ site.baseurl }}/images/1/7.png)
