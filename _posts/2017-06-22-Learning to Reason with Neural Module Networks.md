---
layout: post
title: Learning to Reason with Neural Module Networks
---
دیروز با شروع به کار BAIR (وب لاگ آزمایشگاه تحقیقات هوش مصنوعی دانشگاه بروکلین ) بالاخره این تصمیم رو گرفتم که یه وبلاگ ایجاد کنم.در اولین پست خودم تصمیم گرفتم که اولین پست BAIR رو در وب لاگم قرار بدم .

فرض کنید داریم یک رباط خانگی ایجاد میکنیم و قصد ما از ایجاد این رباط پاسخ به سوالات در باره محیط اطرافمان است . ممکنه سوالاتی مثل سوالات زیر بپرسیم :
![_config.yml]({{ site.baseurl }}/images/1/1.png)

چطور میتونیم مطمین شیم که رباط ما میتونه به درستی به این سوالات پاسخ بده ؟ رویکرد رایج در یادگیری عمیق جمع آوری یک دیتا بیس با حجم عظیم از سوالات ، عکس ها و پاسخ ها است و آموزش یک شبکه عصبی که سوالات و عکس ها رو به صورت مستقیم به جواب ها نگاشت میده. اگه سوالات ما شبیه سوالی که در سمت چپ تصویر است باشند این مسئله یک مسئله رایج تشخیص اشیاء است که متد های معمول بسیر موثر خواهند بود:
![_config.yml]({{ site.baseurl }}/images/1/2.png)

اما این رویکرد برای سئوال زیر به درستی عمل نخواهد کرد:

![_config.yml]({{ site.baseurl }}/images/1/3.png)

شبکه ای که ما قبلا آموزش داده ایم بعد از تسلیم شدن رنگی که از همه رایج تر هست را پیش بینی میکند. چه چیزی این سوال رو سخت تر میکنه ؟با وجود اینکه عکس ما واضح تر است اما سوال نیاز به تعداد زیادی گام استدلال دارد . در این عکس مدل به جای تشخیص شئی اصلی در عکس بایستی ابتدا استوانه آبی رنگ رو پیدا کنه ، محل سایر اشیایی که اندازه برابر رو با استوانه ما داره رو انتخاب کنه و سپس رنگ اون رو مشخص کنه.
این یه محاسباتی پیچیده است ، محاسباتی که به طور خاص مربوط به سوالی که پرسیده شده است. س.الات متفاوت نیاز به مراحل متفاوت از گام ها برای حل شدن دارند.
پارادایم رایج در یادگیری عمیق رویکرد one size fits all است : یرای هر مسئله ای که ما در تلاش برای حل آن هستیم ، ما یک معماری ثابت را ایجاد میکنیم با این امید که بتواند اررتباطات بین ورودی و خروجی را ظبط کند و پارامتر هایی را برای مدل ثابت از داده های آموزش یاد بگیرد.

 اما در استدلالی که در دنیای واقعی انجام میشود به این صورت کار نمیکند : 
