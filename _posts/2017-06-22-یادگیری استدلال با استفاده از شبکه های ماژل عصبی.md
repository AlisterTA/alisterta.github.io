---
layout: post
title: یادگیری استدلال با استفاده از شبکه های ماژل عصبی
---
دیروز با شروع به کار [BAIR]( http://bair.berkeley.edu/) (وب لاگ آزمایشگاه تحقیقات هوش مصنوعی دانشگاه بروکلین ) این تصمیم رو گرفتم که یه وبلاگ ایجاد کنم.در اولین پست خودم تصمیم گرفتم که اولین پست BAIR رو در وب لاگم قرار بدم .

فرض کنید داریم یک رباط خانگی ایجاد میکنیم و منظور ما از ایجاد این رباط پاسخ به سوالات درباره محیط اطرافمان است . ممکنه سوالاتی مثل سوالات زیر بپرسیم :

![_config.yml]({{ site.baseurl }}/images/1/1.png)

چطور میتونیم مطمین شیم که رباط ما میتونه به درستی به این سوالات پاسخ بده ؟ رویکرد رایج در یادگیری عمیق جمع آوری یک دیتا بیس با حجم عظیم از سوالات ، عکس ها و پاسخ ها است و آموزش یک شبکه عصبی که سوالات و عکس ها رو به صورت مستقیم به جواب ها نگاشت میده. اگه سوالات ما شبیه سوالی که در سمت چپ تصویر است باشند این مسئله یک مسئله رایج تشخیص اشیاء است که متد های معمول بسیر موثر خواهند بود:

![_config.yml]({{ site.baseurl }}/images/1/2.png)

اما این رویکرد برای سئوال زیر به درستی عمل نخواهد کرد:

![_config.yml]({{ site.baseurl }}/images/1/3.png)

شبکه ای که ما قبلا آموزش داده ایم بعد از تسلیم شدن رنگی که از همه رایج تر هست را پیش بینی میکند. چه چیزی این سوال رو سخت تر میکنه ؟با وجود اینکه عکس ما واضح تر است اما سوال نیاز به تعداد زیادی گام استدلال دارد . در این عکس مدل به جای تشخیص شئی اصلی در عکس بایستی ابتدا استوانه آبی رنگ رو پیدا کنه ، محل سایر اشیایی که اندازه برابر رو با استوانه ما داره رو انتخاب کنه و سپس رنگ اون رو مشخص کنه.
این یه محاسباتی پیچیده است ، محاسباتی که به طور خاص مربوط به سوالی که پرسیده شده است. س.الات متفاوت نیاز به مراحل متفاوت از گام ها برای حل شدن دارند.
پارادایم رایج در یادگیری عمیق رویکرد one size fits all است : یرای هر مسئله ای که ما در تلاش برای حل آن هستیم ، ما یک معماری ثابت را ایجاد میکنیم با این امید که بتواند اررتباطات بین ورودی و خروجی را ظبط کند و پارامتر هایی را برای مدل ثابت از داده های آموزش یاد بگیرد.

 اما استدلال های دنیای واقعی به این صورت کار نمیکند : این استدلال های شامل انواع متفاوتی از توانایی ها ، که از ترکیب روش های جدیدی برای هر چالش که ما به آن برمیخوریم است. پیزی که ما احتیاج داریم یک مدل است که به صورت پویا تعیین میکند که چگونه در مورد مسئله پیش روی آن استدلال کند ، یک شبکه که میتواند ساختار خود را در حال اجرا انتخاب کند . در این پست ما در مورد یک مجموعه جدید از مدل ها به نام شبکه های ماژول عصبی (NMNs) صحبت خواهیم کرد ، که یک رویکرد انعطاف پذیر را برای حل مشکل در نظر میگیرد که یادیگیری عمیق را بسیار موثر تر میکند.

پیش از این ، مراحل مختلفی برای حل پاسخ دادن به سوال بالا وجود دارند : پیدا کردن یک استوانه آبی ، پیدا کردن شیی با اندازه مشابه و در نهایت مشخص کردن رنگ آن. این مراحل رو میشه به صورت زیر نشان داد :

![_config.yml]({{ site.baseurl }}/images/1/4.png)

یک سوال متفاوت ممکنه شامل مجموعه متفاوتی از گام ها باشد. اگر ما سوال کنیم " چند شیی هم اندازه توپ است ؟" ، ما فلوچارتی مانند شکل زیر ممکن است داشته باشیم:

![_config.yml]({{ site.baseurl }}/images/1/5.png)

 عملیات اصلی مثل "مقایسه اندازه" بین سوالات اشتراک گذاشته میشوند ، اما در مسیر های مختلفی استفاده میشوند. ایده اصلی NMNs  این است که این اشتراک را آشگکار سازیم . ما از دو شبکه متفاوت برای جواب دادن به دو سوال بالا استفاده میکنیم  اما وزن ها را بین بین بخش های شبکه ها که عملیات مشابهی را انجام میدهند به اشتراک میگذاریم:
 
 ![_config.yml]({{ site.baseurl }}/images/1/6.png)
 
 چگونه میتوان مدلی  مانند این را یاد گرفت؟ به جای آموزش یک شبکه بزرگ بر روی تعداد زیادی از ورودی و خروجی ها ، ما در واقع تعداد زیادی از شبکه های متفاوتی را در یک زمان آموزش میدهیم در حالیکه پارامتر های آنها در جاهایی که مناسب است به یک دیگر گره خورده اند:

![_config.yml]({{ site.baseurl }}/images/1/7.png)

چیزی که ما در پایان فرآیند آموزش داریم تنها یک شبکه عمیق  نیست بلکه مجموعه ای از "ماژول های" عصبی است ، که هر یک از آنها یک گام استدلال را پیاده سازی میکند . هنگام استفاده مدل آموزش داده شده ما بر روی یک مسئله جدید ما میتونیم این ماژول ها رو به صورت پویا روی هم سوار کنیم و یک ساختار شبکه جدیل مختص اون مسلله خاص ایجاد کنیم.
یکی از موارد قابل توجه در مورد این فرآیند اینه که ما هیچ نیازی به نظارت سطح پایین برای ماژول های خاص نداریم ، مدل هیچ وقت یک مثال از  تنها از شیی آبی یا یک رابطه  تمام شده را نمیبیند . ماژول ها فقط در داخل یک ساختار بزرگتر یاد میگیرد تنها توسط جفت های سوال و پاسخ به عنوان نظارت. اما فرآیند آموزش قادر است به صورت "خودکار" به رابطه بین بخش هایی از ساختار و محاسباتی که مسئول آن هستند پی ببرد :

![_config.yml]({{ site.baseurl }}/images/1/8.png)

فرآیند مشاابهی برای پاسخ به یک عکس های واقعی تر و حتی سایر منابع دانش از قبیل دیتابیس ها   جواب میدهد :

![_config.yml]({{ site.baseurl }}/images/1/9.png)

جزء کلیدی در تمام این فرآیند یک مجموعه از “طرح های استدلال” سطح بالا مانند شکل بالا است . این طرح ها به ما میگن که به چگونه شبکه برای هر کدام از از سوالات بایستی نمایش بدهد و چگونه سوالات متفاوت به یک دیگر رابطه دارند.اما این طرح های کلی از کجا میآیند؟
در شروع کار بر روی این مدل ها (https://arxiv.org/abs/1511.02799)[1] و (https://arxiv.org/abs/1601.01705)[2]، ما به یک رابطه عجیب بین مسئله طراحی شبکه های عصبی مختص سوال و مشکل تجزیه و تحلیل  ساختار گرامری نزدیک شدیم . زبان شناسان قبلا متوجه شده اند که گرامر سوال به صورت نزدیک به دنباله مراحل محاسباتی برای پاسخ به آن وابسته است.  با توجه به پیشرفت های اخیر در NLP ما میتونیم از ابزار های اماده برای تجزیه و تحلیل گرامری برای آماده کردن نسخه های تقریبی از این طرح ها به صورت خودکار فراهم کنیم.
با یافتن نگاشت صحیح از ساختار زبان شناسی به ساختار شبکه هنوز یک چالش است و این فرایند تبدیل مستعد خطاهایی هست . در کارهای بعد به جای تکیه کردن بر روی این نوع از آنالیز زبانشناسی ، ما به سمت داده های تولید شده توسط کارشناسان انسانیکسانی که مستقیما یک مجموعه از سوالات با طرح های استدلال ایده آل تغییر جهش میدهیم.[3]( https://arxiv.org/abs/1611.09978) با یادگیری تقلید این انسانها مدل ما تئانست کیفیت پیش بینی ها را به صورت اساسی بهبود دهد. شگفت آور اینکه ، زمانی ما یک مدل آموزش داده شده را برای تقلید کارشناسان انتخاب میکنیم اما این اجازه را دارد که الاحات خودش را برای پیش بینی این کارشناسان جستجو کند ، که توانست راه حل های حتی بهتری از کارشناسان بر روی سوالات متفاوت پیدا کند.

علارغم موفقیت قابل توجه متد های یادگیری عمیق در سال های اخیر ، بسیاری از مسائل نظیر  few-shot learning و complex reasoning به صورت یک چالش باقی میمانند. NMNs در زمینه ها بینایی و کارهای استدلال متنی موفقیت هایی را بدست آورده است و ما مشتاق هستیم در آنها را در سایر  مسائل هوش مصنوعی بکار ببریم.
در مقاله ای ذکر شده از دو دیتا بیس [VAQ]( http://www.visualqa.org/) و (http://cs.stanford.edu/people/jcjohns/clevr/)[CLEVR] استفاده شده است.




