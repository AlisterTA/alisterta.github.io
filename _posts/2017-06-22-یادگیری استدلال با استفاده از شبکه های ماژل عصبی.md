---
layout: post
title: یادگیری استدلال با استفاده از شبکه های ماژل عصبی
---
دیروز با شروع به کار [BAIR]( http://bair.berkeley.edu/) (وب لاگ آزمایشگاه تحقیقات هوش مصنوعی دانشگاه بروکلین ) این تصمیم رو گرفتم که یه وبلاگ ایجاد کنم.در اولین پست خودم تصمیم گرفتم که اولین پست BAIR رو در وب لاگم قرار بدم .

فرض کنید داریم یک رباط خانگی طراحی میکنیم و هدف ما از ایجاد این رباط پاسخ به سوالات درباره محیط اطرافمان است . ممکنه سوالاتی مثل سوالات زیر بپرسیم :

![_config.yml]({{ site.baseurl }}/images/1/1.png)

چطور میتونیم مطمین شیم که رباط ما میتونه به درستی به این سوالات پاسخ بده ؟ رویکرد رایج در یادگیری عمیق جمع آوری یک دیتا بیس با حجم عظیم از سوالات ، عکس ها و پاسخ ها و در نهایت آموزش یک شبکه عصبی که سوالات و عکس ها رو به صورت مستقیم به جواب ها نگاشت میده. اگه سوالات ما شبیه سوالی که در سمت چپ تصویر است باشند این مسئله یک مسئله رایج تشخیص اشیاء است که متد های معمول بسیار موثر خواهند بود:

![_config.yml]({{ site.baseurl }}/images/1/2.png)

اما این رویکرد برای سئوال زیر به درستی عمل نخواهد کرد:

![_config.yml]({{ site.baseurl }}/images/1/3.png)

شبکه ای که ما قبلا آموزش داده ایم بعد از تسلیم شدن رنگی که از همه رایج تر هست را پیش بینی میکند. **چه چیزی این سوال رو سخت تر میکنه ؟** با وجود اینکه عکس ما واضح تر است اما سوال نیاز به تعداد زیادی گام استدلال دارد . در این عکس مدل به جای تشخیص شئی اصلی در عکس بایستی ابتدا استوانه آبی رنگ رو پیدا کنه ، محل سایر اشیایی که اندازه برابر رو با استوانه ما داره رو انتخاب کنه و سپس رنگ اون رو مشخص کنه.
این یه محاسباتی پیچیده است ، محاسباتی که مختص سوال پرسیده شده است. سوالات متفاوت نیاز به مراحل مختلف استدلال برای حل شدن دارند.
پارادایم رایج در یادگیری عمیق رویکرد one size fits all (یک سایز به اندازه همه) است : برای هر مسئله ای که ما در تلاش برای حل آن هستیم ، ما یک معماری ثابت را ایجاد میکنیم با این امید که بتواند ارتباطات بین ورودی و خروجی را استخراج کند و پارامتر هایی را برای مدل ثابت از داده های آموزش یاد بگیرد.

 اما استدلال های دنیای واقعی به این صورت کار نمیکند : این استدلال های شامل انواع متفاوتی از توانایی ها ، که از ترکیب روش های جدیدی برای هر چالش که ما به آن برمیخوریم است. چیزی که ما احتیاج داریم یک مدل است که به صورت پویا تعیین میکند که چگونه در مورد مسئله پیش روی آن استدلال کند ، یک شبکه که میتواند ساختار خود را در حال اجرا انتخاب کند . در این پست ما در مورد یک مجموعه جدید از مدل ها به نام **شبکه های ماژول عصبی** [NMNs]( https://arxiv.org/abs/1511.02799) صحبت خواهیم کرد ، یک رویکرد انعطاف پذیر را برای حل مشکل در نظر میگیرد که یادیگیری عمیق را بسیار موثر تر میکند.

پیش از این ، ما متوجه شدیم که مراحل مختلفی برای حل پاسخ دادن به سوال بالا وجود دارد : پیدا کردن یک استوانه آبی ، پیدا کردن شیی با اندازه مشابه و در نهایت مشخص کردن رنگ آن. این مراحل رو میشه به صورت زیر نشان داد :

![_config.yml]({{ site.baseurl }}/images/1/4.png)

یک سوال متفاوت ممکنه شامل مجموعه متفاوتی از گام ها باشد. اگر ما سوال کنیم "چند شیی هم اندازه توپ است ؟" ، ممکنه ما فلوچارتی مانند شکل زیر داشته باشیم:

![_config.yml]({{ site.baseurl }}/images/1/5.png)

 عملیات اصلی مثل "مقایسه اندازه" بین سوالات به اشتراک گذاشته میشود ، اما در مسیر های مختلفی مورد استفاده قرار میگیرند. ایده اصلی NMNs  این است که این اشتراک را نمایان سازیم . ما از دو شبکه متفاوت برای جواب دادن به دو سوال بالا استفاده میکنیم  اما وزن ها را بین بخش های شبکه ها که عملیات مشابهی را انجام میدهند به اشتراک میگذاریم:
 
 ![_config.yml]({{ site.baseurl }}/images/1/6.png)
 
 چگونه میتوان مدلی  مانند این را یاد گرفت؟ به جای آموزش یک شبکه بزرگ بر روی تعداد زیادی از ورودی و خروجی ها ، ما در واقع تعداد زیادی از شبکه های متفاوتی را در یک زمان آموزش میدهیم در حالیکه پارامتر های آنها در جاهایی که مناسب است به یک دیگر گره خورده اند:

![_config.yml]({{ site.baseurl }}/images/1/7.png)

چیزی که ما در پایان فرآیند آموزش داریم تنها یک شبکه عمیق  نیست بلکه مجموعه ای از "ماژول های" عصبی است ، که هر یک از آنها یک گام استدلال را پیاده سازی میکند . در زمان استفاده مدل آموزش داده شده بر روی یک مسئله جدید، ما میتونیم این ماژول ها رو به صورت پویا روی هم سوار کنیم و یک ساختار شبکه جدید مختص اون مسلله خاص ایجاد کنیم.
یکی از موارد قابل توجه در مورد این فرآیند اینه که ما هیچ نیازی به نظارت سطح پایین برای ماژول های خاص نداریم ، مدل هیچ وقت یک مثال تنها از شیی آبی یا یک رابطه  تمام شده را نمیبیند . ماژول ها فقط درداخل یک ساختار بزرگتر رابطه بین سوالا ت و پاسخ ها را با نظارت یاد میگیرند.اما فرآیند آموزش قادر است به صورت "خودکار" به رابطه بین بخش هایی از ساختار و محاسباتی که مسئول آن هستند پی ببرد :

![_config.yml]({{ site.baseurl }}/images/1/8.png)

فرآیند مشابهی نیز برای پاسخ به عکس های واقعی تر و حتی سایر منابع دانش از قبیل دیتابیس ها عمل میکند :

![_config.yml]({{ site.baseurl }}/images/1/9.png)

جزء کلیدی در تمام این فرآیند یک مجموعه از “طرح های استدلال” سطح بالا مانند شکل بالا است . این طرح ها به ما میگن که چگونه شبکه برای هر کدام از سوالات بایستی روی هم قرار گرفته شه و چگونه سوالات متفاوت با یک دیگر رابطه دارند.اما این طرح های کلی از کجا میآیند؟
در شروع کار بر روی این مدل ها [1](https://arxiv.org/abs/1511.02799) و [2](https://arxiv.org/abs/1601.01705)، ما به یک رابطه عجیب بین مسئله طراحی شبکه های عصبی مختص سوال و مشکل تجزیه و تحلیل  ساختار گرامری نزدیک شدیم . زبان شناسان قبلا متوجه شده اند که گرامر سوال به صورت نزدیک به دنباله مراحل محاسباتی برای پاسخ به آن وابسته است.  با توجه به پیشرفت های اخیر در NLP ما میتونیم از ابزار های آماده برای تجزیه و تحلیل گرامری و نسخه های تقریبی از این طرح ها به صورت خودکار فراهم کنیم.
یافتن نگاشت صحیح از ساختار زبان شناسی به ساختار شبکه هنوز یک چالش است و این فرایند تبدیل مستعد خطا هست . در کارهای بعد به جای تکیه کردن بر روی این نوع از آنالیز زبانشناسی ، ما به سمت داده های تولید شده توسط کارشناسان انسانی ، کسانی که مستقیما یک مجموعه از سوالات با طرح های استدلال ایده آل را برچسب گذاری کرده اند تغییر جهت میدهیم.[3]( https://arxiv.org/abs/1611.09978)  با یادگیری تقلید این انسانها مدل ما توانست کیفیت پیش بینی ها را به صورت اساسی بهبود دهد. شگفت آور اینکه ، زمانی ما یک مدل آموزش داده شده را برای تقلید کارشناسان انتخاب میکنیم این اجازه را نیز دارد که حالات خودش را برای پیش بینی اصلاح کند این مدل که توانست راه حل های حتی بهتری از کارشناسان بر روی سوالات متفاوت پیدا کند.

علارغم موفقیت قابل توجه متد های یادگیری عمیق در سال های اخیر ، بسیاری از مسائل نظیر  few-shot learning و complex reasoning به صورت یک چالش باقی میمانند. NMNs در زمینه ها بینایی و کارهای استدلال متنی موفقیت هایی را بدست آورده است و ما مشتاق هستیم در آنها را سایر مسائل هوش مصنوعی بکار ببریم.
در مقاله ای ذکر شده از دو دیتا بیس [VAQ]( http://www.visualqa.org/) و [CLEVR](http://cs.stanford.edu/people/jcjohns/clevr/) استفاده شده است.


![_config.yml]({{ site.baseurl }}/images/1/10.png)

در شکل بالا یک نمایش شماتیک از مدل پیشنهاد شده در [2](https://arxiv.org/abs/1511.02799)نمایش داده شده است . ناحیه خاکستری رنگ در واقع شبکه عصبی ماژولی (NMN) هست که ارایه شده است .این مقاله نتایج خوبی بر روی دیتا بیس VAQ که به تازگی منتشر شده بدست می آورد هد چند بیشتر سوالات موجود در این دیتا بیس ساده هستند و نیاز به استدلال زیادی ندارند.کد این مقاله در[این لینک](https://github.com/jacobandreas/nmn2) موجود است.
